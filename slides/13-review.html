<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Fraida Fund">
  <title>Intro ML Review</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js-master/dist/reset.css">
  <link rel="stylesheet" href="reveal.js-master/dist/reveal.css">
  <style>
    .reveal .sourceCode {  /* see #7635 */
      overflow: visible;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="reveal.js-master/dist/theme/white.css" id="theme">
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Intro ML Review</h1>
  <p class="author">Fraida Fund</p>
</section>

<section id="intro-ml-review" class="title-slide slide level2">
<h2>Intro ML review</h2>
<p>(Not comprehensive!)</p>
</section>

<section>
<section id="what-to-know-about-each-model"
class="title-slide slide level2">
<h2>What to know about each model</h2>

</section>
<section id="make-decisions-about-setting-it-up" class="slide level3">
<h3>Make decisions about setting it up</h3>
</section>
<section id="compute-its-output" class="slide level3">
<h3>Compute its output</h3>
</section>
<section id="train-for-one-step" class="slide level3">
<h3>Train for one step</h3>
</section>
<section id="what-kinds-of-relationships-it-can-learn"
class="slide level3">
<h3>What kinds of relationships it can learn</h3>
</section>
<section id="what-it-costs-for-traininginference" class="slide level3">
<h3>What it costs for training/inference</h3>
</section>
<section id="what-insight-we-get-from-it-once-trained"
class="slide level3">
<h3>What insight we get from it, once trained</h3>
<p>e.g. what its parameters mean</p>
</section>
<section id="how-to-manage-its-biasvariance" class="slide level3">
<h3>How to manage its bias/variance</h3>
</section>
<section id="what-the-pieces-mean" class="slide level3">
<h3>What the “pieces” mean</h3>
</section>
<section id="what-the-visualizations-mean" class="slide level3">
<h3>What the visualizations mean</h3>
</section></section>
<section>
<section id="not-models-but-know-about"
class="title-slide slide level2">
<h2>Not models, but know about…</h2>

</section>
<section id="metrics" class="slide level3">
<h3>Metrics</h3>
</section>
<section id="evaluation-and-cross-validation" class="slide level3">
<h3>Evaluation and cross validation</h3>
</section>
<section id="gradient-descent" class="slide level3">
<h3>Gradient descent</h3>
</section>
<section id="feature-selectionweighting" class="slide level3">
<h3>Feature selection/weighting</h3>
</section>
<section id="hyperparameter-optimization" class="slide level3">
<h3>Hyperparameter optimization</h3>
</section></section>
<section>
<section id="case-studies-to-review" class="title-slide slide level2">
<h2>Case studies to review</h2>

</section>
<section id="data-leakage-case-studies" class="slide level3">
<h3>Data leakage case studies</h3>
<ul>
<li>Beauty in the Classroom<br />
</li>
<li>COVID Case Prediction<br />
</li>
<li>Pre-term Birth Prediction<br />
</li>
<li>Husky vs. Wolf Classification</li>
</ul>
</section>
<section id="fairness-and-bias-case-studies" class="slide level3">
<h3>Fairness and bias case studies</h3>
<ul>
<li>COMPAS Recidivism Prediction<br />
</li>
<li>Gender Bias in Word Embeddings</li>
</ul>
</section>
<section id="using-learned-coefficients-case-studies"
class="slide level3">
<h3>Using learned coefficients case studies</h3>
<ul>
<li>Beauty in the Classroom<br />
</li>
<li>Advertising + PCA Follow-up<br />
</li>
<li>Husky vs. Wolf Classification</li>
</ul>
</section>
<section id="re-thinking-good-enough-case-studies" class="slide level3">
<h3>Re-thinking “good enough” case studies</h3>
<ul>
<li>Beauty in the Classroom<br />
</li>
<li>ICU Mortality Prediction</li>
</ul>
</section>
<section id="moving-beyond-out-of-the-box-case-studies"
class="slide level3">
<h3>Moving beyond “out of the box” case studies</h3>
<ul>
<li>Reading a Monkey Brain<br />
</li>
<li>Voter Classification<br />
</li>
<li>UAV-assisted Wireless Localization</li>
</ul>
</section></section>
<section id="code" class="title-slide slide level2">
<h2>Code</h2>

</section>

<section>
<section id="getting-data" class="title-slide slide level2">
<h2>Getting data</h2>

</section>
<section id="pandas-read-data-from-file" class="slide level3">
<h3><code>pandas</code>: read data from file</h3>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">&quot;data.csv&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_table(<span class="st">&quot;data.txt&quot;</span>, sep<span class="op">=</span><span class="st">&quot;</span><span class="ch">\t</span><span class="st">&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_excel(<span class="st">&quot;data.xlsx&quot;</span>, sheet_name<span class="op">=</span><span class="st">&quot;Sheet1&quot;</span>)</span></code></pre></div>
<p>Common arguments: <code>sep</code>, <code>header</code>,
<code>index_col</code></p>
</section>
<section id="numpy-read-data-from-file" class="slide level3">
<h3><code>numpy</code>: read data from file</h3>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.load(<span class="st">&quot;X.npy&quot;</span>)  </span></code></pre></div>
</section>
<section id="pandas-to-numpy" class="slide level3">
<h3><code>pandas</code> to <code>numpy</code></h3>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.to_numpy()</span></code></pre></div>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.values <span class="co"># older way</span></span></code></pre></div>
</section>
<section id="numpy-to-pandas" class="slide level3">
<h3><code>numpy</code> to <code>pandas</code></h3>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(X, columns<span class="op">=</span>[<span class="st">&quot;a&quot;</span>,<span class="st">&quot;b&quot;</span>,<span class="st">&quot;c&quot;</span>])</span></code></pre></div>
</section>
<section id="pandas-stacking-columns" class="slide level3">
<h3><code>pandas</code>: stacking columns</h3>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.concat([df1, df2], axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<p><small> (Seen in: L6) </small></p>
</section>
<section id="numpy-stacking-columns" class="slide level3">
<h3><code>numpy</code>: stacking columns</h3>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.column_stack([X1, X2])</span></code></pre></div>
</section>
<section id="numpy-reshape-2d-to-1d" class="slide level3">
<h3><code>numpy</code>: reshape 2D to 1D</h3>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> X.reshape(<span class="op">-</span><span class="dv">1</span>,)       <span class="co"># flatten to 1D</span></span></code></pre></div>
</section>
<section id="numpy-reshape-1d-to-2d" class="slide level3">
<h3><code>numpy</code>: reshape 1D to 2D</h3>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> x.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)   <span class="co"># shape (n, 1)</span></span></code></pre></div>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> x.reshape(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)   <span class="co"># shape (1, n)</span></span></code></pre></div>
</section>
<section id="numpy-statistics-by-axis" class="slide level3">
<h3><code>numpy</code>: statistics by axis</h3>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> np.mean(X, axis<span class="op">=</span><span class="dv">0</span>)    <span class="co"># mean of each column</span></span></code></pre></div>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> np.mean(X, axis<span class="op">=</span><span class="dv">1</span>)    <span class="co"># mean of each row</span></span></code></pre></div>
<p>Common statistics: <code>std</code>, <code>min</code>,
<code>max</code>, <code>quantile</code>…</p>
</section></section>
<section>
<section id="preprocessing-data" class="title-slide slide level2">
<h2>Preprocessing data</h2>

</section>
<section id="ordinal-encoding" class="slide level3">
<h3>Ordinal encoding</h3>
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>map_dict <span class="op">=</span> {<span class="st">&#39;18-29&#39;</span>: <span class="dv">1</span>, <span class="st">&#39;30-44&#39;</span>: <span class="dv">2</span>, <span class="st">&#39;45-64&#39;</span>: <span class="dv">3</span>, <span class="st">&#39;65+&#39;</span>: <span class="dv">4</span>}</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>df_enc_ord <span class="op">=</span> pd.DataFrame( </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    {<span class="st">&#39;age&#39;</span>: df[<span class="st">&#39;age&#39;</span>].<span class="bu">map</span>( map_dict) },</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    index <span class="op">=</span> df.index</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><small> (Seen in: L6) </small></p>
</section>
<section id="one-hot-encoding" class="slide level3">
<h3>One-hot encoding</h3>
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># encode one column</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> pd.get_dummies(df[<span class="st">&quot;col&quot;</span>], dtype<span class="op">=</span>np.int32)</span></code></pre></div>
<p><small> (Seen in: L6) </small></p>
</section>
<section id="pandas-converting-string-to-datetime" class="slide level3">
<h3><code>pandas</code>: converting string to datetime</h3>
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&quot;date&quot;</span>] <span class="op">=</span> pd.to_datetime(df[<span class="st">&quot;date&quot;</span>])</span></code></pre></div>
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&quot;date&quot;</span>] <span class="op">=</span> pd.to_datetime(df[<span class="st">&quot;date&quot;</span>], <span class="bu">format</span><span class="op">=</span><span class="st">&quot;%Y-%m-</span><span class="sc">%d</span><span class="st">&quot;</span>)</span></code></pre></div>
<p><small> (Seen in: Week 1 Exploratory Data Analysis Colab lesson + a
few times in HW) </small></p>
</section>
<section id="pandas-sort-by-value-of-column" class="slide level3">
<h3><code>pandas</code>: sort by value of column</h3>
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> df.sort_values(by<span class="op">=</span><span class="st">&quot;col&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> df.sort_values(by<span class="op">=</span>[<span class="st">&quot;col1&quot;</span>, <span class="st">&quot;col2&quot;</span>])</span></code></pre></div>
<p>Common arguments: <code>ascending</code></p>
<p><small> (Seen in: Week 1 Exploratory Data Analysis Colab lesson, Week
4 Model Selection Colab lesson, H4 K-fold CV with Fourier basis
expansion) </small></p>
</section>
<section id="numpy-sort-by-value-of-column" class="slide level3">
<h3><code>numpy</code>: sort by value of column</h3>
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> np.argsort(X[:, <span class="dv">0</span>])   </span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>X2 <span class="op">=</span> X[idx]</span></code></pre></div>
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sort by col0, then col1</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> np.lexsort((X[:, <span class="dv">1</span>], X[:, <span class="dv">0</span>]))</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>X2 <span class="op">=</span> X[idx]</span></code></pre></div>
<p><small> (Seen in: L6 when breaking ties) </small></p>
</section>
<section id="pandas-drop-missing-values" class="slide level3">
<h3><code>pandas</code>: drop missing values</h3>
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># drop rows with ANY missing values</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> df.dropna()                     </span></code></pre></div>
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># drop rows missing specific column by name</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> df.dropna(subset<span class="op">=</span>[<span class="st">&quot;col1&quot;</span>])      </span></code></pre></div>
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># drop rows missing in either column</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>df2 <span class="op">=</span> df.dropna(subset<span class="op">=</span>[<span class="st">&quot;col1&quot;</span>,<span class="st">&quot;col2&quot;</span>])   </span></code></pre></div>
<p><small> (Seen in: L6 when computing feature weights, H4
TimeSeriesSplit question) </small></p>
</section>
<section id="numpy-drop-missing-values" class="slide level3">
<h3><code>numpy</code>: drop missing values</h3>
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># drop rows with ANY missing values</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> np.isnan(X).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>) <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>X2 <span class="op">=</span> X[mask]</span></code></pre></div>
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># drop rows missing in either column by index</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">2</span>]</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> np.isnan(X[:, cols]).<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>) <span class="op">==</span> <span class="dv">0</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>X2 <span class="op">=</span> X[mask]</span></code></pre></div>
</section>
<section id="pandas-impute-missing-values" class="slide level3">
<h3><code>pandas</code>: impute missing values</h3>
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># forward fill, data must be sorted </span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&quot;col&quot;</span>] <span class="op">=</span> df[<span class="st">&quot;col&quot;</span>].fillna(method<span class="op">=</span><span class="st">&quot;ffill&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># using a statistic, only use stats of training set</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> df_tr[<span class="st">&quot;col&quot;</span>].mean() <span class="co"># use training data only</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>df_tr[<span class="st">&quot;col&quot;</span>] <span class="op">=</span> df_tr[<span class="st">&quot;col&quot;</span>].fillna(s)  </span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>df_ts[<span class="st">&quot;col&quot;</span>] <span class="op">=</span> df_ts[<span class="st">&quot;col&quot;</span>].fillna(s)  </span></code></pre></div>
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># using a constant</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>df[<span class="st">&quot;col&quot;</span>] <span class="op">=</span> df[<span class="st">&quot;col&quot;</span>].fillna(<span class="dv">0</span>) </span></code></pre></div>
<p><small> (Seen in: Week 1 Exploratory Data Analysis Colab lesson, H5
ICU mortality prediction) </small></p>
</section>
<section id="numpy-impute-missing-values" class="slide level3">
<h3><code>numpy</code>: impute missing values</h3>
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># applies to all columns</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co"># using a statistic, only use stats of training set</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> np.nanmean(Xtr, axis<span class="op">=</span><span class="dv">0</span>) <span class="co"># use training data only</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>Xtr2 <span class="op">=</span> np.where(np.isnan(Xtr), s, Xtr)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>Xts2 <span class="op">=</span> np.where(np.isnan(Xts), s, Xts)</span></code></pre></div>
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># applies to all columns</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="co"># using a constant</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>X2 <span class="op">=</span> np.where(np.isnan(X), <span class="dv">0</span>, X)</span></code></pre></div>
</section>
<section id="numpy-standardize" class="slide level3">
<h3><code>numpy</code>: Standardize</h3>
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>x_mean <span class="op">=</span> np.mean(X[idx_tr], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>x_std  <span class="op">=</span> np.std(X[idx_tr], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>Xtr_std <span class="op">=</span> (X[idx_tr] <span class="op">-</span> x_mean) <span class="op">/</span> x_std</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>Xts_std <span class="op">=</span> (X[idx_ts] <span class="op">-</span> x_mean) <span class="op">/</span> x_std</span></code></pre></div>
</section>
<section id="scikit-learn-standardize" class="slide level3">
<h3><code>scikit-learn</code>: Standardize</h3>
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>Xtr_std <span class="op">=</span> scaler.fit_transform(X[idx_tr])</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>Xts_std <span class="op">=</span> scaler.transform(X[idx_ts]) </span></code></pre></div>
<p><small> (Seen in: Week 4 Regularization Colab lesson) </small></p>
</section>
<section id="numpy-min-max-scale" class="slide level3">
<h3><code>numpy</code>: Min-max scale</h3>
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>x_min <span class="op">=</span> np.<span class="bu">min</span>(X[idx_tr], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>x_max <span class="op">=</span> np.<span class="bu">max</span>(X[idx_tr], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>Xtr_mm <span class="op">=</span> (X[idx_tr] <span class="op">-</span> x_min) <span class="op">/</span> (x_max <span class="op">-</span> x_min)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>Xts_mm <span class="op">=</span> (X[idx_ts] <span class="op">-</span> x_min) <span class="op">/</span> (x_max <span class="op">-</span> x_min)</span></code></pre></div>
</section>
<section id="scikit-learn-min-max-scale" class="slide level3">
<h3><code>scikit-learn</code>: Min-max scale</h3>
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> MinMaxScaler()</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>Xtr_mm <span class="op">=</span> scaler.fit_transform(X[idx_tr])</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>Xts_mm <span class="op">=</span> scaler.transform(X[idx_ts])</span></code></pre></div>
<p><small> (Seen in: L6) </small></p>
</section>
<section id="scikit-learn-countvectorizer" class="slide level3">
<h3><code>scikit-learn</code>: <code>CountVectorizer</code></h3>
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>vect <span class="op">=</span> CountVectorizer()</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>Xtr <span class="op">=</span> vect.fit_transform(text_tr)     <span class="co"># fit on training text</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>Xts <span class="op">=</span> vect.transform(text_ts)         <span class="co"># transform test text</span></span></code></pre></div>
<p>Common arguments: <code>stop_words</code></p>
<p><small> (Seen in: H5) </small></p>
</section>
<section id="create-transformed-features" class="slide level3">
<h3>Create “transformed” features</h3>
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.assign(interaction <span class="op">=</span> df[<span class="st">&quot;col1&quot;</span>] <span class="op">*</span> df[<span class="st">&quot;col2&quot;</span>])</span></code></pre></div>
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># interaction of col0 and col1</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>interaction <span class="op">=</span> X[:, <span class="dv">0</span>] <span class="op">*</span> X[:, <span class="dv">1</span>]       </span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>X_new <span class="op">=</span> np.column_stack([X, interaction])</span></code></pre></div>
<p><small> (Seen in: L2) </small></p>
</section>
<section id="oversamplingundersampling" class="slide level3">
<h3>Oversampling/undersampling</h3>
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>ovr <span class="op">=</span> ADASYN(n_neighbors <span class="op">=</span> <span class="dv">5</span>, random_state <span class="op">=</span> random_state)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>X_ovr, y_ovr <span class="op">=</span> ovr.fit_resample(X, y)</span></code></pre></div>
<p><small> (Seen in: H8) </small></p>
</section></section>
<section>
<section id="slicing-and-selecting" class="title-slide slide level2">
<h2>Slicing and selecting</h2>

</section>
<section id="pandas-select-columns" class="slide level3">
<h3><code>pandas</code>: select columns</h3>
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>col <span class="op">=</span> df[<span class="st">&quot;col&quot;</span>]                <span class="co"># one column (Series)</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> df[[<span class="st">&quot;col1&quot;</span>, <span class="st">&quot;col2&quot;</span>]]    <span class="co"># list of columns (DataFrame)</span></span></code></pre></div>
</section>
<section id="numpy-select-columns" class="slide level3">
<h3><code>numpy</code>: select columns</h3>
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> X[:, <span class="dv">3</span>]          <span class="co"># one column by index</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> X[:, <span class="dv">2</span>:<span class="dv">5</span>]        <span class="co"># contiguous columns (2,3,4)</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> X[:, [<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">7</span>]]  <span class="co"># list of columns</span></span></code></pre></div>
</section>
<section id="pandas-select-rows" class="slide level3">
<h3><code>pandas</code>: select rows</h3>
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># by integer position - use .iloc</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>rows <span class="op">=</span> df.iloc[<span class="dv">5</span>]        </span></code></pre></div>
<div class="sourceCode" id="cb44"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># by condition</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>rows <span class="op">=</span> df[df[<span class="st">&quot;cola&quot;</span>] <span class="op">&gt;</span> <span class="dv">0</span>] </span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>rows <span class="op">=</span> df[(df[<span class="st">&quot;cola&quot;</span>] <span class="op">&gt;</span> <span class="dv">0</span>) <span class="op">&amp;</span> (df[<span class="st">&quot;colb&quot;</span>] <span class="op">&lt;</span> <span class="dv">5</span>)]</span></code></pre></div>
</section>
<section id="numpy-select-rows" class="slide level3">
<h3><code>numpy</code>: select rows</h3>
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> X[<span class="dv">5</span>]          <span class="co"># one row</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> X[<span class="dv">10</span>:<span class="dv">20</span>]      <span class="co"># slice of rows</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>r <span class="op">=</span> X[[<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">7</span>]]  <span class="co"># list of row indices</span></span></code></pre></div>
<div class="sourceCode" id="cb46"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># by condition on column 0</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>mask <span class="op">=</span> X[:, <span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">0</span>      </span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>X2 <span class="op">=</span> X[mask] </span></code></pre></div>
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># by condition using argwhere</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> np.argwhere(X[:, <span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">0</span>).reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>X2 <span class="op">=</span> X[idx]</span></code></pre></div>
</section>
<section id="sklearn-train_test_split" class="slide level3">
<h3><code>sklearn</code>: train_test_split</h3>
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># split X and y together</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>Xtr, Xts, ytr, yts <span class="op">=</span> train_test_split(</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">0</span>, shuffle<span class="op">=</span><span class="va">True</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb49"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># split X only</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>Xtr, Xts <span class="op">=</span> train_test_split(X, test_size<span class="op">=</span><span class="dv">100</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
<p>Common arguments: <code>test_size</code> (ratio or number),
<code>shuffle</code>, <code>random_state</code></p>
</section>
<section id="sklearn-groupshufflesplit" class="slide level3">
<h3><code>sklearn</code>: GroupShuffleSplit</h3>
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>gss <span class="op">=</span> GroupShuffleSplit(test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>train_idx, test_idx <span class="op">=</span> <span class="bu">next</span>(gss.split(X, y, groups))</span></code></pre></div>
</section>
<section id="sklearn-stratifiedshufflesplit" class="slide level3">
<h3><code>sklearn</code>: StratifiedShuffleSplit</h3>
<div class="sourceCode" id="cb51"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>sss <span class="op">=</span> StratifiedShuffleSplit(test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>train_idx, test_idx <span class="op">=</span> <span class="bu">next</span>(sss.split(X, y))</span></code></pre></div>
</section>
<section id="python-loop-with-index-and-value" class="slide level3">
<h3><code>python</code>: loop with index and value</h3>
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, x <span class="kw">in</span> <span class="bu">enumerate</span>(X):</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># do stuff with i = index, x = row (X is 2D)</span></span></code></pre></div>
</section>
<section id="sklearn-kfold-with-numpy-array" class="slide level3">
<h3><code>sklearn</code>: KFold with <code>numpy</code> array</h3>
<div class="sourceCode" id="cb53"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>kf <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">5</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (idx_tr, idx_ts) <span class="kw">in</span> <span class="bu">enumerate</span>(kf.split(X)):</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>    Xtr, Xts <span class="op">=</span> X[idx_tr], X[idx_ts]</span></code></pre></div>
</section>
<section id="sklearn-kfold-with-pandas-data-frame" class="slide level3">
<h3><code>sklearn</code>: KFold with <code>pandas</code> data frame</h3>
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>kf <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">5</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (idx_tr, idx_ts) <span class="kw">in</span> <span class="bu">enumerate</span>(kf.split(X)):</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>    Xtr, Xts <span class="op">=</span> X.iloc[idx_tr], X.iloc[idx_ts]</span></code></pre></div>
<p>Note the use of <code>iloc</code>! (Applies to all the “variants,”
too.)</p>
</section>
<section id="sklearn-timeseriessplit" class="slide level3">
<h3><code>sklearn</code>: TimeSeriesSplit</h3>
<div class="sourceCode" id="cb55"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>tscv <span class="op">=</span> TimeSeriesSplit(n_splits<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (idx_tr, idx_ts) <span class="kw">in</span> <span class="bu">enumerate</span>(tscv.split(X)):</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>    Xtr, Xts <span class="op">=</span> X[idx_tr], X[idx_ts]</span></code></pre></div>
</section>
<section id="sklearn-groupkfold" class="slide level3">
<h3><code>sklearn</code>: GroupKFold</h3>
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>gkf <span class="op">=</span> GroupKFold(n_splits<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (idx_tr, idx_ts) <span class="kw">in</span> <span class="bu">enumerate</span>(gkf.split(X, groups)):</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>    Xtr, Xts <span class="op">=</span> X[idx_tr], X[idx_ts]</span></code></pre></div>
<p>Comment: groups by <code>groups</code></p>
</section>
<section id="sklearn-stratifiedkfold" class="slide level3">
<h3><code>sklearn</code>: StratifiedKFold</h3>
<div class="sourceCode" id="cb57"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>skf <span class="op">=</span> StratifiedKFold(n_splits<span class="op">=</span><span class="dv">5</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (idx_tr, idx_ts) <span class="kw">in</span> <span class="bu">enumerate</span>(skf.split(X, y)):</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>    Xtr, Xts <span class="op">=</span> X[idx_tr], X[idx_ts]</span></code></pre></div>
<p>Comment: stratifies by <code>y</code></p>
</section>
<section id="sklearn-gridsearchcv" class="slide level3">
<h3><code>sklearn</code>: GridSearchCV</h3>
<div class="sourceCode" id="cb58"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> [</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>  {<span class="st">&#39;C&#39;</span>: [<span class="fl">1e-1</span>, <span class="fl">1e1</span>, <span class="fl">1e3</span>], <span class="st">&#39;gamma&#39;</span>: [<span class="fl">1e2</span>, <span class="dv">1</span>, <span class="fl">1e-1</span>, <span class="fl">1e-3</span>]},</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a> ]</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>grid <span class="op">=</span> GridSearchCV(model, param_grid, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>grid.fit(Xtr, ytr)</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>best <span class="op">=</span> grid.best_params_</span></code></pre></div>
<p><small> (Seen in: H8) </small></p>
</section>
<section id="one-se-rule" class="slide level3">
<h3>One-SE rule</h3>
<ul>
<li><strong>Step 1</strong>: Find models within one SE of “best”
model</li>
<li><strong>Step 2</strong>: Pick the simplest model from the list of
candidates</li>
</ul>
</section>
<section id="one-se-rule-step-1-with-lower-is-better-metric"
class="slide level3">
<h3>One-SE rule: Step 1 with lower-is-better metric</h3>
<div class="sourceCode" id="cb59"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># score_val is a lower-is-better metric</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="co"># so threshold is: SMALLEST mean score PLUS its std/(nfold-1)</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>idx_min <span class="op">=</span> np.argmin(score_val.mean(axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> score_val[idx_min,:].mean() <span class="op">+</span> score_val[idx_min,:].std()<span class="op">/</span>np.sqrt(nfold<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a><span class="co"># candidate models have mean score BELOW that threshold</span></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>idx_one_se <span class="op">=</span> np.where(score_val.mean(axis<span class="op">=</span><span class="dv">1</span>) <span class="op">&lt;=</span> target)</span></code></pre></div>
</section>
<section id="one-se-rule-step-1-with-higher-is-better-metric"
class="slide level3">
<h3>One-SE rule: Step 1 with higher-is-better metric</h3>
<div class="sourceCode" id="cb60"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># score_val is a higher-is-better metric</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="co"># so threshold is: LARGEST mean score MINUS its std/(nfold-1)</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>idx_min <span class="op">=</span> np.argmax(score_val.mean(axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>target <span class="op">=</span> score_val[idx_min,:].mean() <span class="op">-</span> score_val[idx_min,:].std()<span class="op">/</span>np.sqrt(nfold<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a><span class="co"># candidate models have mean score ABOVE that threshold</span></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>idx_one_se <span class="op">=</span> np.where(score_val.mean(axis<span class="op">=</span><span class="dv">1</span>) <span class="op">&gt;=</span> target)</span></code></pre></div>
</section>
<section
id="one-se-rule-step-2-with-models-ordered-from-least-complex-to-most"
class="slide level3">
<h3>One-SE rule: Step 2 with models ordered from least complex to
most</h3>
<div class="sourceCode" id="cb61"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get LOWEST indexed model (least complex)</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>m_one_se <span class="op">=</span> np.<span class="bu">min</span>(model_list[idx_one_se])</span></code></pre></div>
</section>
<section
id="one-se-rule-step-2-with-models-ordered-from-most-complex-to-least"
class="slide level3">
<h3>One-SE rule: Step 2 with models ordered from most complex to
least</h3>
<div class="sourceCode" id="cb62"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get HIGHEST indexed model (least complex)</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>m_one_se <span class="op">=</span> np.<span class="bu">max</span>(model_list[idx_one_se])</span></code></pre></div>
</section></section>
<section>
<section id="metrics-1" class="title-slide slide level2">
<h2>Metrics</h2>

</section>
<section id="regression-metrics" class="slide level3">
<h3>Regression metrics</h3>
<div class="sourceCode" id="cb63"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y, y_pred)</span></code></pre></div>
<div class="sourceCode" id="cb64"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>mae <span class="op">=</span> mean_absolute_error(y, y_pred)</span></code></pre></div>
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># r2_score(y_true, y_pred) — order matters: true first, pred second</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>r2  <span class="op">=</span> r2_score(y, y_pred)</span></code></pre></div>
<p>Comment: <code>y</code> and <code>y_pred</code> must have same
shape…</p>
</section>
<section id="numpy-prediction-by-mean" class="slide level3">
<h3><code>numpy</code>: prediction by mean</h3>
<div class="sourceCode" id="cb66"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ones * mean, works by broadcasting</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> np.mean(ytr)</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>pred_mean <span class="op">=</span> np.ones(y.shape) <span class="op">*</span> m</span></code></pre></div>
<div class="sourceCode" id="cb67"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fill array with mean</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> np.mean(ytr)</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>pred_mean <span class="op">=</span> np.full_like(y, m)</span></code></pre></div>
<div class="sourceCode" id="cb68"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># repeat mean </span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> np.mean(ytr)</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>pred_mean <span class="op">=</span> np.repeat(m, <span class="bu">len</span>(y))          </span></code></pre></div>
<p>Comment: use training data only to compute mean! then can fill all of
<code>y</code> or just <code>ytr</code> or <code>yts</code>.</p>
</section>
<section id="classification-metrics-label-based" class="slide level3">
<h3>Classification metrics (label-based)</h3>
<div class="sourceCode" id="cb69"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>acc   <span class="op">=</span> accuracy_score(y, y_pred)</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>bacc  <span class="op">=</span> balanced_accuracy_score(y, y_pred) </span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>f1    <span class="op">=</span> f1_score(y, y_pred)</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>prec  <span class="op">=</span> precision_score(y, y_pred)</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>rec   <span class="op">=</span> recall_score(y, y_pred)</span></code></pre></div>
<p>Comment: <code>y</code> and <code>y_pred</code> must have same
shape…</p>
</section>
<section id="classification-metrics-probability-based"
class="slide level3">
<h3>Classification metrics (probability-based)</h3>
<div class="sourceCode" id="cb70"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># y_proba = probability for class 1</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>y_proba <span class="op">=</span> model.predict_proba(X)[:, <span class="dv">1</span>]  </span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a>auc  <span class="op">=</span> roc_auc_score(y, y_proba)   </span></code></pre></div>
</section>
<section id="numpy-prediction-by-mode" class="slide level3">
<h3><code>numpy</code>: prediction by mode</h3>
<p>Same idea as “prediction by mean”, but to get mode…</p>
<div class="sourceCode" id="cb71"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>vals, counts <span class="op">=</span> np.unique(ytr, return_counts<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="co"># index of most common value in counts array</span></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>m_idx <span class="op">=</span> np.argmax(counts)      </span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="co"># actual label</span></span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> vals[m_idx]               </span></code></pre></div>
<div class="sourceCode" id="cb72"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> mode</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> mode(ytr, keepdims<span class="op">=</span><span class="va">True</span>).mode[<span class="dv">0</span>]</span></code></pre></div>
<p>Comment: use training data only to compute mode!</p>
<p><small> (Seen in: H5 ICU Mortality Prediction, and others)
</small></p>
</section></section>
<section>
<section id="model-fitting-and-prediction"
class="title-slide slide level2">
<h2>Model fitting and prediction</h2>

</section>
<section id="general-pattern" class="slide level3">
<h3>General pattern</h3>
<div class="sourceCode" id="cb73"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># choose model + pass arguments</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Model()   </span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a><span class="co"># train, Xtr MUST be 2D (n_samples, n_features)</span></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>model.fit(Xtr, ytr)    </span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a><span class="co"># predict   </span></span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(Xts) </span></code></pre></div>
<p><small> (Seen in: Week 2 Colab lesson) </small></p>
</section>
<section id="linear-models" class="slide level3">
<h3>Linear models</h3>
<div class="sourceCode" id="cb74"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LinearRegression()</span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Ridge(alpha<span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Lasso(alpha<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LogisticRegression()</span></code></pre></div>
</section>
<section id="nearest-neighbors" class="slide level3">
<h3>Nearest neighbors</h3>
<div class="sourceCode" id="cb75"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">5</span>)</span></code></pre></div>
</section>
<section id="trees-and-ensembles-of-trees" class="slide level3">
<h3>Trees and ensembles of trees</h3>
<div class="sourceCode" id="cb76"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DecisionTreeRegressor(max_depth<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DecisionTreeClassifier(max_depth<span class="op">=</span><span class="dv">5</span>)</span></code></pre></div>
<div class="sourceCode" id="cb77"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">200</span>)</span></code></pre></div>
<div class="sourceCode" id="cb78"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> AdaBoostClassifier(n_estimators<span class="op">=</span><span class="dv">200</span>, learning_rate<span class="op">=</span><span class="fl">0.5</span>)</span></code></pre></div>
</section>
<section id="svm" class="slide level3">
<h3>SVM</h3>
<div class="sourceCode" id="cb79"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">&quot;rbf&quot;</span>, C<span class="op">=</span><span class="fl">1.0</span>, gamma<span class="op">=</span><span class="fl">0.1</span>)</span></code></pre></div>
</section>
<section id="kmeans-clustering" class="slide level3">
<h3>KMeans clustering</h3>
<div class="sourceCode" id="cb80"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">3</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>Xtr_cls <span class="op">=</span> model.fit_predict(Xtr)         <span class="co"># unsupervised: no y</span></span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>Xts_cls <span class="op">=</span> model.predict(Xts) <span class="co"># cluster assignments on new data</span></span></code></pre></div>
</section>
<section id="pca" class="slide level3">
<h3>PCA</h3>
<div class="sourceCode" id="cb81"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>Xtr_pca <span class="op">=</span> pca.fit_transform(Xtr)    <span class="co"># fit PCA on training data</span></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>Xts_pca <span class="op">=</span> pca.transform(Xts)      <span class="co"># apply to test data</span></span></code></pre></div>
</section></section>
<section>
<section id="pytorch-models" class="title-slide slide level2">
<h2>Pytorch models</h2>

</section>
<section id="model-binary-classification-with-prob-output"
class="slide level3">
<h3>Model: Binary classification with prob output</h3>
<div class="sourceCode" id="cb82"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>nout <span class="op">=</span> <span class="dv">1</span>  <span class="co"># !!!</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleNNBinaryClassification(nn.Module):</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, nin, nh, nout):</span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(SimpleNNBinaryClassification, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden <span class="op">=</span> nn.Linear(nin, nh)</span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output <span class="op">=</span> nn.Linear(nh, nout)</span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.sigmoid(<span class="va">self</span>.hidden(x))</span>
<span id="cb82-12"><a href="#cb82-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.sigmoid(<span class="va">self</span>.output(x))  <span class="co"># !!!</span></span>
<span id="cb82-13"><a href="#cb82-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb82-14"><a href="#cb82-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-15"><a href="#cb82-15" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SimpleNNBinaryClassification(nin, nh, nout)</span>
<span id="cb82-16"><a href="#cb82-16" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.BCELoss() <span class="co"># !!!</span></span>
<span id="cb82-17"><a href="#cb82-17" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>)</span></code></pre></div>
</section>
<section id="model-binary-classification-with-logit-output"
class="slide level3">
<h3>Model: Binary classification with logit output</h3>
<div class="sourceCode" id="cb83"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>nout <span class="op">=</span> <span class="dv">1</span>  <span class="co"># !!!</span></span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleNNBinaryClassificationLogits(nn.Module):</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, nin, nh, nout):</span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(SimpleNNBinaryClassificationLogits, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden <span class="op">=</span> nn.Linear(nin, nh)</span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output <span class="op">=</span> nn.Linear(nh, nout)</span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-10"><a href="#cb83-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb83-11"><a href="#cb83-11" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.sigmoid(<span class="va">self</span>.hidden(x))</span>
<span id="cb83-12"><a href="#cb83-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.output(x) <span class="co"># !!!</span></span>
<span id="cb83-13"><a href="#cb83-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb83-14"><a href="#cb83-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-15"><a href="#cb83-15" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SimpleNNBinaryClassificationLogits(nin, nh, nout)</span>
<span id="cb83-16"><a href="#cb83-16" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.BCEWithLogitsLoss() <span class="co"># !!!</span></span>
<span id="cb83-17"><a href="#cb83-17" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>)</span></code></pre></div>
</section>
<section id="model-multi-class-classification-with-log-prob-output"
class="slide level3">
<h3>Model: Multi-class classification with log prob output</h3>
<div class="sourceCode" id="cb84"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>nout <span class="op">=</span> <span class="dv">3</span> <span class="co"># !!!</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleNNMultiClassification(nn.Module):</span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, nin, nh, nout):</span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(SimpleNNMultiClassification, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden <span class="op">=</span> nn.Linear(nin, nh)</span>
<span id="cb84-8"><a href="#cb84-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output <span class="op">=</span> nn.Linear(nh, nout)</span>
<span id="cb84-9"><a href="#cb84-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-10"><a href="#cb84-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb84-11"><a href="#cb84-11" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.sigmoid(<span class="va">self</span>.hidden(x))</span>
<span id="cb84-12"><a href="#cb84-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.log_softmax(<span class="va">self</span>.output(x), dim<span class="op">=</span><span class="dv">1</span>) <span class="co"># !!!</span></span>
<span id="cb84-13"><a href="#cb84-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb84-14"><a href="#cb84-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-15"><a href="#cb84-15" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SimpleNNMultiClassification(nin, nh, nout)</span>
<span id="cb84-16"><a href="#cb84-16" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.NLLLoss() <span class="co"># !!!</span></span>
<span id="cb84-17"><a href="#cb84-17" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>)</span></code></pre></div>
</section>
<section id="model-multi-class-classification-with-logit-output"
class="slide level3">
<h3>Model: Multi-class classification with logit output</h3>
<div class="sourceCode" id="cb85"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>nout <span class="op">=</span> <span class="dv">3</span> <span class="co"># !!!</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleNNMultiClassificationLogits(nn.Module):</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, nin, nh, nout):</span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(SimpleNNMultiClassificationLogits, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden <span class="op">=</span> nn.Linear(nin, nh)</span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output <span class="op">=</span> nn.Linear(nh, nout)</span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-10"><a href="#cb85-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb85-11"><a href="#cb85-11" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.sigmoid(<span class="va">self</span>.hidden(x))</span>
<span id="cb85-12"><a href="#cb85-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.output(x) <span class="co"># !!!</span></span>
<span id="cb85-13"><a href="#cb85-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb85-14"><a href="#cb85-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-15"><a href="#cb85-15" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SimpleNNMultiClassificationLogits(nin, nh, nout)</span>
<span id="cb85-16"><a href="#cb85-16" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()  <span class="co"># !!!</span></span>
<span id="cb85-17"><a href="#cb85-17" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>)</span></code></pre></div>
</section>
<section id="model-regression-with-one-output" class="slide level3">
<h3>Model: Regression with one output</h3>
<div class="sourceCode" id="cb86"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>nout <span class="op">=</span> <span class="dv">1</span>  <span class="co"># !!!</span></span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleNNRegression(nn.Module):</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, nin, nh, nout):</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(SimpleNNRegression, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden <span class="op">=</span> nn.Linear(nin, nh)</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output <span class="op">=</span> nn.Linear(nh, nout)</span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.sigmoid(<span class="va">self</span>.hidden(x))</span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.output(x) <span class="co"># !!!</span></span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb86-14"><a href="#cb86-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-15"><a href="#cb86-15" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SimpleNNRegression(nin, nh, nout)</span>
<span id="cb86-16"><a href="#cb86-16" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.MSELoss() <span class="co"># !!!</span></span>
<span id="cb86-17"><a href="#cb86-17" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>)</span></code></pre></div>
</section>
<section id="model-regression-with-multi-output" class="slide level3">
<h3>Model: Regression with multi output</h3>
<div class="sourceCode" id="cb87"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>nout <span class="op">=</span> <span class="dv">2</span>  <span class="co"># !!!</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleNNMultiRegression(nn.Module):</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, nin, nh, nout):</span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(SimpleNNMultiRegression, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden <span class="op">=</span> nn.Linear(nin, nh)</span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output <span class="op">=</span> nn.Linear(nh, nout)</span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb87-11"><a href="#cb87-11" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.sigmoid(<span class="va">self</span>.hidden(x))</span>
<span id="cb87-12"><a href="#cb87-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.output(x) <span class="co"># !!!</span></span>
<span id="cb87-13"><a href="#cb87-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb87-14"><a href="#cb87-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-15"><a href="#cb87-15" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SimpleNNMultiRegression(nin, nh, nout)</span>
<span id="cb87-16"><a href="#cb87-16" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.MSELoss() <span class="co"># !!!</span></span>
<span id="cb87-17"><a href="#cb87-17" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>)</span></code></pre></div>
</section>
<section id="predictions-binary-classification-with-prob-output"
class="slide level3">
<h3>Predictions: binary classification with prob output</h3>
<div class="sourceCode" id="cb88"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> model(X) </span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> (outputs <span class="op">&gt;</span> <span class="fl">0.5</span>).<span class="bu">int</span>() </span></code></pre></div>
</section>
<section id="predictions-binary-classification-with-logit-output"
class="slide level3">
<h3>Predictions: binary classification with logit output</h3>
<div class="sourceCode" id="cb89"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>    logits <span class="op">=</span> model(X)</span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> torch.sigmoid(logits)</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> (outputs <span class="op">&gt;</span> <span class="fl">0.5</span>).<span class="bu">int</span>() </span></code></pre></div>
</section>
<section id="predictions-multi-class-classification-either-output-type"
class="slide level3">
<h3>Predictions: multi-class classification, either output type</h3>
<div class="sourceCode" id="cb90"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> model(X)              </span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> torch.argmax(outputs, dim<span class="op">=</span><span class="dv">1</span>)  </span></code></pre></div>
</section>
<section id="predictions-regression-any-number-of-outputs"
class="slide level3">
<h3>Predictions: regression, any number of outputs</h3>
<div class="sourceCode" id="cb91"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> model(X)    </span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>    preds <span class="op">=</span> outputs</span></code></pre></div>
</section>
<section id="convnets-convolution-blocks" class="slide level3">
<h3>ConvNets: convolution blocks</h3>
<div class="sourceCode" id="cb92"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Before: (batch_size, n1, H1, W1)</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>nn.Conv2d(n1, n2, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">0</span>), </span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a><span class="co"># After: (batch_size, n2, H2, W2)</span></span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>nn.ReLU(),      <span class="co"># no change in shape</span></span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>nn.BatchNorm2d(n2), <span class="co"># no change in shape</span></span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a>nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">2</span>),                   </span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a><span class="co"># After: (batch_size, n2, H3, W3)</span></span></code></pre></div>
</section>
<section id="convnets-classification-head" class="slide level3">
<h3>ConvNets: classification head</h3>
<div class="sourceCode" id="cb93"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="va">self</span>.classifier <span class="op">=</span> nn.Sequential(</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Before: (batch_size, n, h, w)</span></span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>    nn.Flatten(), </span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># After: (batch_size, n x h x w)</span></span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a>    nn.Linear(n_out_conv, n_out), </span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># After: (batch_size, n_out)</span></span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</section></section>
<section id="general-tips-for-autograding"
class="title-slide slide level2">
<h2>General tips for autograding</h2>
<ul>
<li>run your code beginning to end before submitting to grader</li>
<li>don’t re-use out-of-loop variable names inside loops</li>
<li>keep an eye on <code>#grade</code> tags</li>
</ul>
</section>
    </div>
  </div>

  <script src="reveal.js-master/dist/reveal.js"></script>

  <!-- reveal.js plugins -->
  <script src="reveal.js-master/plugin/notes/notes.js"></script>
  <script src="reveal.js-master/plugin/search/search.js"></script>
  <script src="reveal.js-master/plugin/zoom/zoom.js"></script>
  <script src="reveal.js-master/plugin/math/math.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'default',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: true,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        math: {
          mathjax: '/usr/share/javascript/mathjax/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [
          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    </body>
</html>
