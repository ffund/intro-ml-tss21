<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Fraida Fund">
  <title>Feature selection</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js-master/dist/reset.css">
  <link rel="stylesheet" href="reveal.js-master/dist/reveal.css">
  <style>
    .reveal .sourceCode {  /* see #7635 */
      overflow: visible;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="reveal.js-master/dist/theme/white.css" id="theme">
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Feature selection</h1>
  <p class="author">Fraida Fund</p>
</section>

<section class="slide level3">

<aside class="notes">
<p><strong>Math prerequisites for this lecture</strong>: None.</p>
</aside>
</section>
<section>
<section id="feature-selection-and-feature-weighting"
class="title-slide slide level2">
<h2>Feature selection and feature weighting</h2>
<p>Feature selection is actually two problems:</p>
<ul>
<li>best number of features</li>
<li>best subset of features</li>
</ul>
<aside class="notes">
<p>These problems can be solved separately:</p>
<ul>
<li>find best subset of feature of every possible size</li>
<li>then among those, select the best</li>
</ul>
<p>or they can be solved together, for example:</p>
<ul>
<li>keep adding features until improvement due to another feature is
less than some threshold <span class="math inline">\(t\)</span></li>
<li>keep features whose “score” exceeds some threshold <span
class="math inline">\(t\)</span></li>
<li>etc.</li>
</ul>
<p>For KNN, feature selection:</p>
<ul>
<li>reduces inference time (which scales with <span
class="math inline">\(d\)</span>)</li>
<li>addresses the “curse of dimensionality”</li>
<li>makes the distance measure more useful, by considering only the
features that are most relevant</li>
</ul>
<p>For KNN, we can also do feature weighting (compute a weight for each
feature, scale feature by that weight) as an alternative to (or in
addition to) feature selection - this helps with the third item.</p>
</aside>
<!-- 
### Feature selection is not *independent* of model fitting

Example: suppose a "true" function is

$$t(x) = w_0 x_0 + w_1 x_1 + w_2  (x_3 \oplus x_4) $$

What subset of $[x_0, x_1, x_2, x_3, x_4]$ to select?

:::notes

There is no universal "best feature" subset for a dataset! The "best feature" subset depends on the model we are going to train, and whether the selected features have predictive value *for that model*.

* if your model is a linear model?
* if your model can capture non-linear relationships and interaction effects?

:::

-->
</section>
<section id="feature-selection-is-hard" class="slide level3">
<h3>Feature selection is hard!</h3>
<aside class="notes">
<p>Computationally <strong>hard</strong> - even on small problems. In
practice, we won’t ever have a guarantee of finding the optimal
subset.</p>
</aside>
</section>
<section id="optimization-in-two-parts" class="slide level3">
<h3>Optimization in two parts</h3>
<ul>
<li><strong>Search</strong> the space of possible feature subsets</li>
<li><strong>Evaluate</strong> the goodness of a feature subset</li>
</ul>
<aside class="notes">
<figure>
<img data-src="../images/6-feature-selection.png" style="width:30.0%"
alt="Feature selection problem." />
<figcaption aria-hidden="true">Feature selection problem.</figcaption>
</figure>
</aside>
</section>
<section id="search-exhaustive-search" class="slide level3">
<h3>Search: exhaustive search</h3>
<p><strong>Optimal search</strong>: consider every combination of
features</p>
<ul>
<li>Given <span class="math inline">\(d\)</span> features, there are
<span class="math inline">\(2^d\)</span> possible feature subsets</li>
<li>Too expensive to try all possibilities!</li>
</ul>
</section>
<section id="search-naive-heuristic" class="slide level3">
<h3>Search: naive heuristic</h3>
<ul>
<li>sort <span class="math inline">\(d\)</span> features in order of
“goodness”</li>
<li>select top <span class="math inline">\(k\)</span> features from the
list (use CV to choose <span class="math inline">\(k\)</span>?)</li>
</ul>
<aside class="notes">
<p><strong>Problem</strong>: this approach considers each feature
independently.</p>
<ul>
<li>Doesn’t consider redundancy: if you have two copies of an
informative features, they’ll both score high (but you wouldn’t
necessarily want to include both in your model).</li>
<li>Doesn’t consider interaction: if you are going to use a model that
can learn interactions “natively” (which KNN can!), this type of feature
selection may exclude features that are not informative themselves, but
whose combination is informative.</li>
</ul>
<figure>
<img data-src="../images/6-feature-select-xor-linear.png"
style="width:70.0%"
alt="Example of features that are informative in combination (x_1, x_2), and features that are redundant (x_4, x_5)." />
<figcaption aria-hidden="true">Example of features that are informative
in combination (<span class="math inline">\(x_1, x_2\)</span>), and
features that are redundant (<span class="math inline">\(x_4,
x_5\)</span>).</figcaption>
</figure>
</aside>
</section>
<section id="search-sequential-forward-selection" class="slide level3">
<h3>Search: sequential forward selection</h3>
<ul>
<li>Let <span class="math inline">\(S^{t-1}\)</span> be the set of
selected features at time <span class="math inline">\(t-1\)</span></li>
<li>Train and evaluate model for all combinations of current set + one
more feature</li>
<li>For the next time step <span class="math inline">\(S^t\)</span>, add
the feature that gave you the best performance.</li>
<li>Repeat until termination criterion is satisfied.</li>
</ul>
<aside class="notes">
<p>This is not necessarily going to find the best feature subset! But,
it is a lot faster than the exhaustive search, and is less likely to
include redundant features than naive approach.</p>
</aside>
</section>
<section id="search-sequential-forward-selection-as-a-tree"
class="slide level3">
<h3>Search: sequential forward selection as a tree</h3>
<figure>
<img data-src="../images/6-sequential-forward-tree.png"
style="width:60.0%" alt="Tree representation" />
<figcaption aria-hidden="true">Tree representation</figcaption>
</figure>
</section>
<section id="search-sequential-backward-elimination-as-a-tree"
class="slide level3">
<h3>Search: sequential backward elimination as a tree</h3>
<figure>
<img data-src="../images/6-sequential-reverse-elimnination.png"
style="width:60.0%" alt="Tree representation" />
<figcaption aria-hidden="true">Tree representation</figcaption>
</figure>
<aside class="notes">
<p>“Backward” alternative: start with all features, and “prune” one at a
time.</p>
<p>This is not necessarily going to find the best feature subset! But,
it is a lot faster than the exhaustive search. Compared to “forward”
search it is, more likely to keep features that are useful in
combination with another feature.</p>
<figure>
<img data-src="../images/6-feature-search-strategy.png"
style="width:90.0%" alt="Feature selection search strategies." />
<figcaption aria-hidden="true">Feature selection search
strategies.</figcaption>
</figure>
</aside>
</section>
<section id="evaluation-of-goodness" class="slide level3">
<h3>Evaluation of “goodness”</h3>
<figure>
<img data-src="../images/6-feature-select-categorical.png"
style="width:75.0%" alt="Which feature should you choose?" />
<figcaption aria-hidden="true">Which feature should you
choose?</figcaption>
</figure>
<aside class="notes">
<ul>
<li>When <span class="math inline">\(x_1\)</span> is large, <span
class="math inline">\(y\)</span> tends to be <span
class="math inline">\(1\)</span>; <span
class="math inline">\(x_1\)</span> is small, <span
class="math inline">\(y\)</span> tends to be <span
class="math inline">\(0\)</span> (linear/monotonic relationship)</li>
<li>When <span class="math inline">\(x_2\)</span> is “medium”, <span
class="math inline">\(y\)</span> tends to be 0; <span
class="math inline">\(x_2\)</span> is small or large, <span
class="math inline">\(y\)</span> tends to be 1 (not
linear/monotonic)</li>
<li>Whatever the value of <span class="math inline">\(x_3\)</span>,
either value of <span class="math inline">\(y\)</span> is equally likely
(not useful)</li>
<li>For most values of <span class="math inline">\(x_4\)</span>, it is
not useful for predicting <span class="math inline">\(y\)</span>, but
when <span class="math inline">\(x_4\)</span> is 1, <span
class="math inline">\(y\)</span> tends to be 0.</li>
</ul>
</aside>
</section>
<section id="evaluation-univariate-scoring" class="slide level3">
<h3>Evaluation: univariate scoring</h3>
<p>Pseudocode:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> j <span class="kw">in</span> X.shape[<span class="dv">1</span>]:</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  score[j] <span class="op">=</span> score_fn(X[:,j], y) </span></code></pre></div>
<aside class="notes">
<p>Note: You can also use the score for feature weighting (multiply the
feature by the “score” so that high-scoring features have larger
values): Compared to feature selection, feature weighting does not have
the benefit of faster inference time, but it does have the advantage of
not throwing out useful information.</p>
</aside>
</section>
<section id="evaluation-multivariate-scoring" class="slide level3">
<h3>Evaluation: multivariate scoring</h3>
<p>Pseudocode:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> j, feat_set <span class="kw">in</span> <span class="bu">enumerate</span>(feat_sets):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  score[j] <span class="op">=</span> score_fn(X[:,feat_set], y) </span></code></pre></div>
</section>
<section id="evaluation-model-in-the-loop-scoring" class="slide level3">
<h3>Evaluation: model-in-the-loop scoring</h3>
<p>Pseudocode:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> j, feat_set <span class="kw">in</span> <span class="bu">enumerate</span>(feat_sets):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  score[j] <span class="op">=</span> model.score( X[:,feat_set], y) </span></code></pre></div>
</section>
<section id="evaluation-types-of-methods" class="slide level3">
<h3>Evaluation: “types” of methods</h3>
<ul>
<li><strong>Filter methods</strong>: consider only the statistics of the
training data, don’t use the model.</li>
<li><strong>Wrapper methods</strong>: evaluate subsets of features on a
model.</li>
</ul>
<aside class="notes">
<p>Filter methods are usually much faster - but won’t necessarily find
the features that are optimal <em>for your particular case</em>.</p>
</aside>
</section>
<section id="evaluation-aligning-scoring-function-with-prediction-task"
class="slide level3">
<h3>Evaluation: aligning scoring function with prediction task</h3>
<aside class="notes">
<p>Scoring functions from “least closely aligned with the prediction
task” to “most closely aligned with the prediction task”.</p>
<ul>
<li>using only statistics of <code>X</code> (e.g. reject features with
very low variance) - doesn’t tell you which features are most useful for
predicting <code>y</code>!</li>
<li>using statistics of <code>X, y</code> (e.g. reject features with
small correlation with <code>y</code>) - doesn’t tell you which features
are most useful <em>for your model</em> for predicting
<code>y</code>!</li>
<li>using the score of the model on a validation set when trained on the
feature(s)</li>
</ul>
<p>When <em>would</em> it make sense to reject features with low
variance? Consider a text classification task with indicator variables
for each word in the vocabulary:</p>
<ul>
<li><code>the</code> appears in all documents - not useful.</li>
<li><code>historiography</code> appears in a couple of documents - not
useful.</li>
</ul>
</aside>
</section>
<section id="evaluation-scoring-functions-for-filter-methods-1"
class="slide level3">
<h3>Evaluation: scoring functions for filter methods (1)</h3>
<ul>
<li>Need to choose “scoring” function that is a good fit for the
model</li>
</ul>
<aside class="notes">
<p><strong>Scoring function</strong>:</p>
<ul>
<li>Scoring function measures the relationship between <code>X</code>
and <code>y</code>.</li>
<li>For example: correlation coefficient, or F-statistic both of which
measures linear relationship between <code>X</code> and
<code>y</code>.</li>
</ul>
<p><strong>Problem</strong>: correlation coefficient scoring metric only
captures linear relationship.</p>
<ul>
<li>If you expect the relationship to be linear, it’s fine!</li>
<li>If you are using a model (e.g. linear regression) that is only
capable of learning linear relationships, it’s fine! You don’t want your
feature selection method to give a high score to a column if the model
won’t be able to learn from it anyway.</li>
</ul>
</aside>
</section>
<section id="evaluation-scoring-functions-for-filter-methods-2"
class="slide level3">
<h3>Evaluation: scoring functions for filter methods (2)</h3>
<figure>
<img data-src="../images/6-feature-selection-scoring.png"
style="width:75.0%"
alt="F-test selects x_1 as the most informative feature, MI selects x_2." />
<figcaption aria-hidden="true">F-test selects <span
class="math inline">\(x_1\)</span> as the most informative feature, MI
selects <span class="math inline">\(x_2\)</span>.</figcaption>
</figure>
</section>
<section id="evaluation-wrapper-methods" class="slide level3">
<h3>Evaluation: wrapper methods</h3>
<ul>
<li>Tuned to specific interaction of dataset + model!</li>
<li>Usually much more expensive (especially considering model
hyperparameter tuning…)</li>
</ul>
<aside class="notes">
<figure>
<img data-src="../images/6-wrapper.png" style="width:40.0%"
alt="Using a wrapper method to evaluate different feature subsets, on the same/similar objective to the “real” final ML model." />
<figcaption aria-hidden="true">Using a wrapper method to evaluate
different feature subsets, on the same/similar objective to the “real”
final ML model.</figcaption>
</figure>
</aside>
</section>
<section id="an-option-for-some-models" class="slide level3">
<h3>An option for some models</h3>
<ul>
<li><strong>Embedded methods</strong>: use something built-in to
training algorithm (e.g. LASSO regularization). (Not available for
KNN!)</li>
</ul>
</section>
<section id="recap" class="slide level3">
<h3>Recap</h3>
<ul>
<li><strong>Important</strong>: Don’t use the test set for feature
selection!</li>
<li>Feature selection approach should “match” the data, model</li>
<li>Computation is a concern - it won’t be possible to optimize
everything</li>
</ul>
</section></section>
    </div>
  </div>

  <script src="reveal.js-master/dist/reveal.js"></script>

  <!-- reveal.js plugins -->
  <script src="reveal.js-master/plugin/notes/notes.js"></script>
  <script src="reveal.js-master/plugin/search/search.js"></script>
  <script src="reveal.js-master/plugin/zoom/zoom.js"></script>
  <script src="reveal.js-master/plugin/math/math.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'default',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: true,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [
          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    </body>
</html>
