<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Fraida Fund">
  <title>Working with Data</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="reveal.js-master/dist/reset.css">
  <link rel="stylesheet" href="reveal.js-master/dist/reveal.css">
  <style>
    .reveal .sourceCode {  /* see #7635 */
      overflow: visible;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="reveal.js-master/dist/theme/white.css" id="theme">
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Working with Data</h1>
  <p class="author">Fraida Fund</p>
</section>

<section id="garbage-in-garbage-out" class="title-slide slide level2">
<h2>Garbage in, garbage out</h2>
<aside class="notes">
<p>Any machine learning project has to start with high-quality data.</p>
<p>There is a “garbage in, garbage out” rule: If you use “garbage” to
train a machine learning model, you will only get “garbage” out. (And:
Since you are testing on the same data, you might not even realize it is
“garbage” at first! You may not realize until the model is already
deployed in production!)</p>
</aside>
</section>

<section id="before-using-any-data" class="title-slide slide level2">
<h2>Before using any data</h2>
<ul>
<li>Consider ethics concerns</li>
<li>Prepare a held-out test set</li>
<li>Make and check assumptions</li>
<li>Check for missing data</li>
<li>Identify potentially predictive features</li>
<li>Look for patterns you <em>don’t</em> want model to learn</li>
</ul>
</section>

<section id="ethics-concerns" class="title-slide slide level2">
<h2>Ethics concerns</h2>

</section>

<section id="some-data-ethics-concerns"
class="title-slide slide level2 cell markdown">
<h2>Some data ethics concerns</h2>
<ul>
<li>Bias</li>
<li>Privacy</li>
<li>Consent</li>
</ul>
<p>…are just a few.</p>
<aside class="notes">
<ul>
<li>Many social media datasets used for “offensive post” classification
have biased labels (especially if they were produced without adequate
training procedures in place). For example, they may label posts
containing African-American dialects of English as “offensive” much more
often. <a
href="https://www.aclweb.org/anthology/P19-1163.pdf">Source</a>, <a
href="https://www.vox.com/recode/2019/8/15/20806384/social-media-hate-speech-bias-black-african-american-facebook-twitter">User-friendly
article</a></li>
<li><a
href="http://www.michaelzimmer.org/2008/09/30/on-the-anonymity-of-the-facebook-dataset/">On
the anonymity of the Facebook dataset</a></li>
<li><a
href="https://www.vice.com/en_us/art*cle/8q88nx/70000-okcupid-users-just-had-their-data-published">70,000
OkCupid Users Just Had Their Data Published</a>; <a
href="https://www.wired.com/2016/05/*kcupid-study-reveals-perils-big-data-science/">OkCupid
Study Reveals the Perils of Big-Data Science</a>; <a
href="https://ironholds.org/scientific-consent/">Ethics, scientific
consent and OKCupid</a></li>
<li><a
href="https://www.theverge.com/2019/3/12/18262646/ibm-didnt-inform-people-when-it-used-their-flickr-photos-for-facial-recognition-training">IBM
didn’t inform people when it used their Flickr photos for facial
recognition training</a></li>
</ul>
</aside>
</section>

<section id="prepare-a-held-out-test-set"
class="title-slide slide level2">
<h2>Prepare a held-out test set</h2>
<ul>
<li>If we plan to use some data for machine learning, we <em>must</em>
set aside a “test set” before we do <em>anything</em> with the
data.</li>
<li>We will explain in a future lesson why this is so important.</li>
</ul>
<aside class="notes">
<p>Our next steps - checking assumptions, handling missing data,
identifying potentially predictive features, identifying “bad” patterns
- will be on the part of the data that is not “held out” as a test
set.</p>
</aside>
</section>

<section>
<section id="make-and-check-assumptions"
class="title-slide slide level2">
<h2>Make and check assumptions</h2>
<aside class="notes">
<p>It’s always a good idea to “sanity check” your data - before you look
at it, think about what you expect to see. Then check to make sure your
expectations are realized.</p>
<p>Look at plots of data, summary statistics, etc. and consider general
trends.</p>
</aside>
</section>
<section id="example-author-citation-data-1" class="slide level3">
<h3>Example: author citation data (1)</h3>
<p>Data analysis: use PubMed, and identify the year of first publication
for the 100,000 most cited authors.</p>
<aside class="notes">
<p>What are our expectations about what this should look like?</p>
</aside>
</section>
<section id="example-author-citation-data-2" class="slide level3">
<h3>Example: author citation data (2)</h3>
<figure>
<img data-src="../images/1-pubmed-authors.png" style="width:50.0%"
alt="Does this look reasonable?" />
<figcaption aria-hidden="true">Does this look reasonable?</figcaption>
</figure>
<aside class="notes">
<p>We can think of many potential explanations for this pattern, even
though it is actually a data artifact.</p>
<p>The true explanation: in 2002, PubMed started using full first names
in authors instead of just initials. The same author is represented in
the dataset as a “new” author with a first date of publication in
2002.</p>
</aside>
</section>
<section id="example-author-citation-data-3" class="slide level3">
<h3>Example: author citation data (3)</h3>
<figure>
<img data-src="../images/1-pubmed-authors2.png" style="width:50.0%"
alt="The real distribution, after name unification. Example via Steven Skiena @ Stony Brook U." />
<figcaption aria-hidden="true">The real distribution, after name
unification. Example via <a
href="https://www3.cs.stonybrook.edu/~skiena/519/">Steven Skiena @ Stony
Brook U</a>.</figcaption>
</figure>
<!-- 
### Example: anomalous voting data (1)

![Data like this was widely (wrongly) used as evidence of anomaly in the 2020 U.S. Presidential election.](../images/1-election2020.png){ width=30% }

::: notes

What are our assumptions about election night data, and how are they violated here? 

We expect that per-candidate vote totals (computed by multiplying total votes and vote share) should increase as more votes are counted, but never decrease.

What are possible explanations?

:::

### Example: anomalous voting data (2)

![Process by which data is collected by Edison and AP.](../images/1-election2020-process.png){ width=75% }

::: notes

This anomaly makes a lot of sense as a correction of a data entry or duplicate entry error. 

How Edison/AP collects the data for their Election Night feed:

* There are "stringers" (temporary reporters) at various elections offices who call results into their phone center
* They have people who look at official government websites for new results that they manually enter into the system
* They have people who monitor results sent by fax from counties and cities

all working as fast as they can! Data entry and duplicate entry errors are not only likely, they are almost guaranteed. When they are corrected, vote totals may decrease.

Source: [AP](https://web.archive.org/web/20210410214207/https://www.ap.org/en-us/topics/politics/elections/counting-the-vote), [Edison](http://www.edisonresearch.com/wp-content/uploads/2020/10/Web-Entry-Team-Handout-2020.pdf)

:::

-->
</section>
<section id="handling-unreasonable-data"
class="slide level3 cell markdown">
<h3>Handling unreasonable data</h3>
<aside class="notes">
<p>How should you handle unreasonable values, data that does not match
expectations, or “outliers”? It depends!</p>
<ul>
<li>e.g. suppose in a dataset of voter information, some have impossible
year of birth - would make the voter over 120 years old. (The reason:
Voters with no known DOB, who registered before DOB was required, are
often encoded with a January 1900 DOB.)</li>
<li><strong>not</strong> a good idea to just remove outliers unless you
are sure they are a data entry error or otherwise not a “true”
value.</li>
<li>Even if an outlier is due to some sort of error, if you remove them,
you may skew the dataset (as in the 1/1/1900 voters example).</li>
</ul>
<p>Consider the possibility of:</p>
<ul>
<li>Different units, time zones, etc. in different rows</li>
<li>Same value represented several different ways (e.g. names,
dates)</li>
<li>Missing data encoded as zero</li>
</ul>
</aside>
</section></section>
<section>
<section id="look-for-missing-data" class="title-slide slide level2">
<h2>Look for missing data</h2>

</section>
<section id="indicators-of-missing-data"
class="slide level3 cell markdown">
<h3>Indicators of missing data</h3>
<ul>
<li>Rows that have <code>NaN</code> values</li>
<li>Rows that are <em>not there</em></li>
</ul>
<!-- To do: NYC taxi tip data, NYS thruway data -->
</section>
<section id="examples-of-missing-data"
class="slide level3 cell markdown">
<h3>Examples of missing data</h3>
<aside class="notes">
<ul>
<li>Twitter API terms of use don’t allow researchers to share tweets
directly, only message IDs (except for limited distribution, e.g. by
email). To reproduce the dataset, you use the Twitter API to download
messages using their IDs. But, tweets that have been removed are not
available - the distribution of removed tweets is not flat! (For
example: you might end up with a dataset that has offensive posts but
few “obvious” offensive posts.)</li>
<li>A dataset of Tweets following Hurricane Sandy makes it looks like
Manhattan was the hub of the disaster, because of power blackouts and
limited cell service in the most affected areas. <a
href="https://hbr.org/2013/04/the-hidden-biases-in-big-data">Source</a></li>
<li>The City of Boston released a smartphone app that uses accelerometer
and GPS data to detect potholes and report them automatically. But, low
income and older residents are less likely to have smartphones, so this
dataset presents a skewed view of where potholes are. <a
href="https://hbr.org/2013/04/the-hidden-biases-in-big-data">Source</a></li>
</ul>
</aside>
</section>
<section id="types-of-missingness" class="slide level3 cell markdown">
<h3>Types of “missingness”</h3>
<ul>
<li>Completely random</li>
<li>Correlated with something that is in data</li>
<li>Correlated with something not in data</li>
</ul>
<aside class="notes">
<p>These are often referred to using this standard terminology (which
can be confusing):</p>
<ul>
<li>Missing <em>completely</em> at random: missingness not correlated
with any feature or the target variable.</li>
<li>Missing at random: missingness correlated with something that is in
data.</li>
<li>Missing not at random: missingness correlated with something that is
not in data.</li>
</ul>
</aside>
</section>
<section id="handling-missing-data" class="slide level3 cell markdown">
<h3>Handling missing data</h3>
<p>How should you handle little bits of missing data? It always depends
on the data and the circumstances. Some possibilities include:</p>
<ul>
<li>omit the row</li>
<li>fill with mean, median, max, mode…</li>
<li>fill back/forward (ordered rows)</li>
<li>train a model on the rest of the data to “predict” the missing
value</li>
</ul>
<aside class="notes">
<p>You generally have to know why the data is missing, to understand the
best way to handle it.</p>
</aside>
</section></section>
<section>
<section id="identify-predictive-features"
class="title-slide slide level2">
<h2>Identify predictive features</h2>
<aside class="notes">
<p>“Predictive” means “related to the target variable” (any kind of
relationship!)</p>
</aside>
</section>
<section id="how-do-we-look-for-predictive-features"
class="slide level3 cell markdown">
<h3>How do we look for predictive features?</h3>
<ul>
<li>Numeric (continuous) features</li>
<li>Categorical features</li>
<li>Graphical features</li>
<li>Text features</li>
</ul>
</section></section>
<section>
<section id="bad-patterns-and-data-leakage"
class="title-slide slide level2">
<h2>“Bad patterns” (and data leakage)</h2>
<aside class="notes">
<p>When looking for predictive features, also ask yourself - are there
patterns in the data that you <em>don’t</em> want your model to
learn?</p>
</aside>
</section>
<section id="covid-19-chest-radiography-1" class="slide level3">
<h3>COVID-19 chest radiography (1)</h3>
<ul>
<li><strong>Problem</strong>: diagnose COVID-19 from chest radiography
images</li>
<li><strong>Input</strong>: image of chest X-ray (or other
radiography)</li>
<li><strong>Target variable</strong>: COVID or no COVID</li>
</ul>
</section>
<section id="covid-19-chest-radiography-2" class="slide level3">
<h3>COVID-19 chest radiography (2)</h3>
<figure>
<img data-src="../images/1-covid-xrays.png" style="width:60.0%"
alt="Neural networks can classify the source dataset of these chest X-ray images, even without lungs! Source" />
<figcaption aria-hidden="true">Neural networks can classify the source
dataset of these chest X-ray images, even <em>without lungs</em>! <a
href="https://arxiv.org/abs/2004.12823">Source</a></figcaption>
</figure>
<aside class="notes">
<p>Between January and October 2020, more than 2000 papers were
published that claimed to use machine learning to diagnose COVID-19
patients based on chest X-rays or other radiography. But a later <a
href="https://www.nature.com/articles/s42256-021-00307-0">review</a>
found that “none of the models identified are of potential clinical use
due to methodological flaws and/or underlying biases”.</p>
<p>To train these models, people used an emerging COVID-19 chest X-ray
dataset, along with one or more existing chest X-ray dataset, for
example a pre-existing dataset used to try and classify viral
vs. bacterial pneumonia.</p>
<p>The problem is that the chest X-rays for each dataset were so
“distinctive” to that dataset, that a neural network could be trained
with high accuracy to classify an image into its source dataset, even
without the lungs showing!</p>
</aside>
</section>
<section id="covid-19-chest-radiography-2-1" class="slide level3">
<h3>COVID-19 chest radiography (2)</h3>
<p>Findings:</p>
<ul>
<li>some non-COVID datasets were pediatric images, COVID images were
adult</li>
<li>there were dataset-level differences in patient positioning</li>
<li>many COVID images came from screenshots of published papers, which
often had text, arrows, or other annotations over the images. (Some
non-COVID images did, too.)</li>
</ul>
</section>
<section id="covid-19-chest-radiography-3" class="slide level3">
<h3>COVID-19 chest radiography (3)</h3>
<figure>
<img data-src="../images/1-covid-xrays-saliency.png" style="width:90.0%"
alt="Saliency map showing the “important” pixels for classification. Source" />
<figcaption aria-hidden="true">Saliency map showing the “important”
pixels for classification. <a
href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7523163/">Source</a></figcaption>
</figure>
<aside class="notes">
<p>These findings are based on techniques like</p>
<ul>
<li>saliency maps, where the model is made to highlight the part of the
image (the pixels) that it considered most relevant to its
decision.</li>
<li>using generative models and asking it to take a COVID-negative X-ray
and make it positive (or v.v.)</li>
</ul>
<p>Many of the findings are not easy to understand without domain
knowledge (e.g. knowing what part of the X-ray <em>should</em> be
important and what part should not be.) For example: should the
diaphragm area be helpful?</p>
</aside>
</section>
<section id="data-leakage" class="slide level3">
<h3>Data leakage</h3>
<aside class="notes">
<p>In machine learning, we train models on a training set of data, then
evaluate their performance on a set of data that was not used in
training. “Data leakage” can occur when</p>
<ul>
<li>information “leaks” between the held-out test set and the training
set</li>
<li>or, information from the target variable (that should not/will not
be available when making a prediction) leaks into the feature data</li>
<li>or any scenario where the model may learn a “pattern” that will not
be present during the “real” task.</li>
</ul>
<p>Data leakage: the model uses something (a feature, a pattern in the
data, actual data points) that will not be available during “real”
prediction task.</p>
</aside>
</section>
<section id="some-types-of-data-leakage" class="slide level3">
<h3>Some types of data leakage</h3>
<ul>
<li>Learning from a feature that is a proxy for target variable, but
that won’t be available</li>
<li>Learning from adjacent temporal data</li>
<li>Learning from duplicate data</li>
<li>Learning from features that are not available at prediction time
(e.g. data from the future)</li>
</ul>
</section>
<section id="signs-of-potential-data-leakage-after-training"
class="slide level3">
<h3>Signs of potential data leakage (after training)</h3>
<ul>
<li>Performance is “too good to be true”</li>
<li>Unexpected behavior of model (e.g. learns from a feature that
shouldn’t help)</li>
</ul>
</section>
<section id="detecting-data-leakage" class="slide level3">
<h3>Detecting data leakage</h3>
<ul>
<li>Exploratory data analysis</li>
<li>Study the data before, during, and after you use it!</li>
<li>Explainable ML methods</li>
<li>Early testing in production</li>
</ul>
</section></section>
<section id="many-more-data-problems" class="title-slide slide level2">
<h2>Many more data problems…</h2>
<aside class="notes">
<ul>
<li><strong>Data is not representative of your target
situation</strong>. For example, you are training a model to predict the
spread of infectious disease for a NYC-based health startup, but you are
using data from another country.</li>
<li><strong>Data or situation changes over time</strong>. For example,
imagine you train a machine learning model to classify loan
applications. However, if the economy changes, applicants that were
previously considered credit-worthy might not be anymore despite having
the same income, as the lender becomes more risk-averse. Similarly, if
wages increase across the board, the income standard for a loan would
increase.</li>
</ul>
</aside>
</section>
    </div>
  </div>

  <script src="reveal.js-master/dist/reveal.js"></script>

  <!-- reveal.js plugins -->
  <script src="reveal.js-master/plugin/notes/notes.js"></script>
  <script src="reveal.js-master/plugin/search/search.js"></script>
  <script src="reveal.js-master/plugin/zoom/zoom.js"></script>
  <script src="reveal.js-master/plugin/math/math.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: true,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'bottom-right',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: false,

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: false,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: true,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'default',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: true,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [
          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    </body>
</html>
